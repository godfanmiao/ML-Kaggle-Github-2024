{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1ef9018",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "#《Python机器学习及实践：从零开始通往Kaggle竞赛之路（2024年度版）》开源代码\n",
    "#-----------------------------------------------------------------\n",
    "#                 @章节号：6.6.3（注意力机制的PaddlePaddle实践）                           \n",
    "#                 @作者：范淼、徐晟桐 \n",
    "#                 @购书链接：https://item.jd.com/13482761.html\n",
    "#                 @电子邮箱：fanmiao.cslt.thu@hotmail.com             \n",
    "#                 @官方交流QQ群号：561500762                        \n",
    "##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c57aa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "from paddle import nn, optimizer, metric\n",
    "\n",
    "\n",
    "#设定超参数。\n",
    "INPUT_UNITS = 56\n",
    "TIME_STEPS = 14\n",
    "NUM_HEADS = 1\n",
    "HIDDEN_UNITS = 256\n",
    "NUM_CLASSES = 10\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "\n",
    "class Attention(nn.Layer):\n",
    "    '''\n",
    "    自定义的注意力机制类，继承自nn.Layer。\n",
    "    '''\n",
    "    def __init__(self, input_units, time_steps, num_heads, hidden_units, num_classes):\n",
    "        \n",
    "        super(Attention, self).__init__() \n",
    "        \n",
    "        self.multihead_attn = nn.MultiHeadAttention(embed_dim=input_units, num_heads=num_heads)\n",
    "        \n",
    "        self.l1 = nn.Linear(input_units * time_steps, hidden_units)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.l2 = nn.Linear(hidden_units, num_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "\n",
    "        out = self.multihead_attn(input_tensor, input_tensor, input_tensor)\n",
    "        \n",
    "        out = paddle.reshape(out[0], (-1,784))\n",
    "        \n",
    "        out = self.l1(out)\n",
    "        \n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.l2(out)\n",
    "        \n",
    "        return out \n",
    "    \n",
    "\n",
    "#初始化注意力机制神经网络。\n",
    "paddle_model = Attention(INPUT_UNITS, TIME_STEPS, NUM_HEADS, HIDDEN_UNITS, NUM_CLASSES)\n",
    "\n",
    "model = paddle.Model(paddle_model)\n",
    "\n",
    "#为模型训练做准备，设置优化器，损失函数和评估指标。\n",
    "model.prepare(optimizer=optimizer.Adam(learning_rate=LEARNING_RATE, parameters=model.parameters()),\n",
    "              loss=nn.CrossEntropyLoss(),\n",
    "              metrics=metric.Accuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1278f2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "#使用pandas，读取fashion_mnist的训练和测试数据文件。\n",
    "train_data = pd.read_csv('../datasets/fashion_mnist/fashion_mnist_train.csv')\n",
    "test_data = pd.read_csv('../datasets/fashion_mnist/fashion_mnist_test.csv')\n",
    "\n",
    "#从训练数据中，拆解出训练特征和类别标签。\n",
    "X_train = train_data[train_data.columns[1:]]\n",
    "y_train = train_data['label']\n",
    "\n",
    "#从测试数据中，拆解出测试特征和类别标签。\n",
    "X_test = test_data[train_data.columns[1:]]\n",
    "y_test = test_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41db6804",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "#初始化数据标准化处理器。\n",
    "ss = StandardScaler()\n",
    "\n",
    "#标准化训练数据特征。\n",
    "X_train = ss.fit_transform(X_train)\n",
    "\n",
    "#标准化测试数据特征。\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d117f701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'paddle.nn' has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m TensorDataset([X_train, y_train])\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#启动模型训练，指定训练数据集，设置训练轮次，设置每次数据集计算的批次大小。\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/python_paddle/lib/python3.9/site-packages/paddle/hapi/model.py:1781\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, train_data, eval_data, batch_size, epochs, eval_freq, log_freq, save_dir, save_freq, verbose, drop_last, shuffle, num_workers, callbacks, accumulate_grad_batches, num_iters)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m   1780\u001b[0m     cbks\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch)\n\u001b[0;32m-> 1781\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1782\u001b[0m     cbks\u001b[38;5;241m.\u001b[39mon_epoch_end(epoch, logs)\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m do_eval \u001b[38;5;129;01mand\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m eval_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/python_paddle/lib/python3.9/site-packages/paddle/hapi/model.py:2112\u001b[0m, in \u001b[0;36mModel._run_one_epoch\u001b[0;34m(self, data_loader, callbacks, mode, logs)\u001b[0m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   2109\u001b[0m     _inputs\u001b[38;5;241m.\u001b[39mappend((step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accumulate \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   2110\u001b[0m                    \u001b[38;5;129;01mor\u001b[39;00m step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_loader))\n\u001b[0;32m-> 2112\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_batch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metrics \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss:\n\u001b[1;32m   2115\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m [[l[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m outs[\u001b[38;5;241m0\u001b[39m]]]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/python_paddle/lib/python3.9/site-packages/paddle/hapi/model.py:1102\u001b[0m, in \u001b[0;36mModel.train_batch\u001b[0;34m(self, inputs, labels, update)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, update\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1055\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;124;03m    Run one training step on one batch of data. And using `update` indicates\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;124;03m    whether optimizer update gradients computing by this batch.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;124;03m            # [array([2.192784], dtype=float32)]\u001b[39;00m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1102\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fluid\u001b[38;5;241m.\u001b[39m_non_static_mode() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1104\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inputs()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/python_paddle/lib/python3.9/site-packages/paddle/hapi/model.py:725\u001b[0m, in \u001b[0;36mDynamicGraphAdapter.train_batch\u001b[0;34m(self, inputs, labels, update)\u001b[0m\n\u001b[1;32m    723\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mddp_model(\u001b[38;5;241m*\u001b[39m[to_variable(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m inputs])\n\u001b[1;32m    724\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 725\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mto_variable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    727\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39m_loss(\u001b[38;5;241m*\u001b[39m(to_list(outputs) \u001b[38;5;241m+\u001b[39m labels))\n\u001b[1;32m    728\u001b[0m losses \u001b[38;5;241m=\u001b[39m to_list(losses)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/python_paddle/lib/python3.9/site-packages/paddle/fluid/dygraph/layers.py:948\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m in_declarative_mode()) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks) \\\n\u001b[1;32m    946\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_post_hooks) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_built) \u001b[38;5;129;01mand\u001b[39;00m in_dygraph_mode() \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m in_profiler_mode()):\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_once(\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    950\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dygraph_call_func(\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[0;32mIn[2], line 37\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, input_tensor)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_tensor):\n\u001b[1;32m     35\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultihead_attn(input_tensor, input_tensor, input_tensor)\n\u001b[0;32m---> 37\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m(out[\u001b[38;5;241m0\u001b[39m], (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m784\u001b[39m))\n\u001b[1;32m     39\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml1(out)\n\u001b[1;32m     41\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'paddle.nn' has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "from paddle.io import TensorDataset\n",
    "\n",
    "X_train = X_train.reshape([-1, TIME_STEPS, INPUT_UNITS])\n",
    "\n",
    "X_train = paddle.to_tensor(X_train.astype('float32'))\n",
    "\n",
    "y_train = y_train.values\n",
    "\n",
    "#构建适用于PaddlePaddle模型训练的数据集。\n",
    "train_dataset = TensorDataset([X_train, y_train])\n",
    "\n",
    "#启动模型训练，指定训练数据集，设置训练轮次，设置每次数据集计算的批次大小。\n",
    "model.fit(train_dataset, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c754d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape([-1, TIME_STEPS, INPUT_UNITS])\n",
    "\n",
    "X_test = paddle.to_tensor(X_test.astype('float32'))\n",
    "\n",
    "y_test = y_test.values\n",
    "\n",
    "#构建适用于PaddlePaddle模型测试的数据集。\n",
    "test_dataset = TensorDataset([X_test, y_test])\n",
    "\n",
    "#启动模型测试，指定测试数据集。\n",
    "result = model.evaluate(test_dataset, verbose=0)\n",
    "\n",
    "print('注意力机制（PaddlePaddle版本）在fashion_mnist测试集上的准确率为: %.2f%%。' %(result['acc'] * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
